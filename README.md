# ğŸ“ Projekt Zaliczeniowy z Uczenia Maszynowego

**Autorzy:**  
- Artiom Herashchenko  
- Maksym Kudlai  
- Oleksandr Burmahin  

---

## ğŸ“Œ Opis Projektu

Projekt stanowi kompleksowe opracowanie zagadnieÅ„ z zakresu uczenia maszynowego. Obejmuje rÃ³Å¼ne techniki â€“ od klasycznych modeli, przez sieci neuronowe, aÅ¼ po zaawansowane metody optymalizacji.  
Kod zostaÅ‚ podzielony na moduÅ‚y odpowiadajÄ…ce poszczegÃ³lnym zadaniom i progom zaliczeniowym (3.0 â€“ 5.0).

---

## ğŸ—‚ï¸ Struktura Projektu

| Plik | Opis |
|------|------|
| `generate_subs.py` | Skrypt do generowania syntetycznego zbioru danych `subscribers.xlsx`. |
| `analiza_subskrybentow.py` | (Na 3.0) Klasyfikacja binarna przy uÅ¼yciu Naiwnego Bayesa i Drzewa Decyzyjnego (scikit-learn). |
| `sieci_dwuwarstwowe.py` | (Na 3.0) Prosta dwuwarstwowa sieÄ‡ neuronowa (PyTorch) â€” problem XOR i zbiÃ³r Titanic. |
| `MNIST.py` | (Na 3.0) Konwolucyjna sieÄ‡ neuronowa do klasyfikacji cyfr (zbiÃ³r MNIST). |
| `laborka_na_4.0.py` | (Na 4.0) Analiza zbioru Iris â€” EDA, Drzewo Decyzyjne i MLP z wykorzystaniem scikit-learn. |
| `laborka_na5.0.py` | (Na 5.0) RÄ™czna implementacja optymalizatorÃ³w (Momentum, Adagrad) bez torch.optim, generowanie raportu PDF. |

---

## ğŸ§  Zastosowane Techniki

### âœ… Poziom 3.0 â€“ Fundamenty

- **Klasyczne modele (Naive Bayes, Decision Tree)**  
  Przetwarzanie danych za pomocÄ… `Pipeline`, kodowanie cech, skalowanie, wizualizacja wynikÃ³w (ROC, confusion matrix).

- **Sieci neuronowe (XOR, Titanic)**  
  WÅ‚asna implementacja dwuwarstwowej sieci neuronowej z wizualizacjÄ… gradientÃ³w.

- **CNN â€“ MNIST**  
  Konwolucyjna sieÄ‡ neuronowa z ReLU, MaxPooling, FC. Skuteczna klasyfikacja obrazÃ³w.

---

### âœ… Poziom 4.0 â€“ Eksploracja i modelowanie

- **Exploratory Data Analysis (EDA)**  
  Analiza zbioru Iris â€” pairploty, rozkÅ‚ad cech.

- **PorÃ³wnanie modeli**  
  Drzewo Decyzyjne i MLPClassifier (scikit-learn), wizualizacja drzewa i krzywa uczenia.

---

### âœ… Poziom 5.0 â€“ Optymalizacja

- **Momentum**  
  Przyspiesza uczenie poprzez akumulacjÄ™ gradientÃ³w.

- **Adagrad**  
  Adaptacyjny wspÃ³Å‚czynnik uczenia â€“ osobny dla kaÅ¼dego parametru.

- **PorÃ³wnanie skutecznoÅ›ci optymalizatorÃ³w**  
  WÅ‚asnorÄ™cznie napisana pÄ™tla uczÄ…ca, wizualizacja wynikÃ³w, automatyczny raport PDF.

---

## â–¶ï¸ Jak UruchomiÄ‡

1. **Instalacja zaleÅ¼noÅ›ci**  
   Zalecane Å›rodowisko: Python 3.9+  
   Zainstaluj wymagane pakiety:

   ```bash
   pip install -r requirements.txt